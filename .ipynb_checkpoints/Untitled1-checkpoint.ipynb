{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bf09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 239\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_logs)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [1], line 229\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    224\u001b[0m     net_config \u001b[38;5;241m=\u001b[39m NetworkConfiguration(n_channels \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m48\u001b[39m),\n\u001b[1;32m    225\u001b[0m                                         kernel_sizes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m    226\u001b[0m                                         strides \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    227\u001b[0m                                         dense_hiddens \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m    228\u001b[0m                                         )\n\u001b[0;32m--> 229\u001b[0m     trainer_obj \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnet_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnet_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mactivation_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     train_logs \u001b[38;5;241m=\u001b[39m trainer_obj\u001b[38;5;241m.\u001b[39mtrain_loop(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_logs)\n",
      "Cell \u001b[0;32mIn [1], line 35\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, network_type, net_config, lr, batch_size, activation_name)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_dataset()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_type \u001b[38;5;241m=\u001b[39m network_type\n\u001b[0;32m---> 35\u001b[0m activation_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_activation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m network_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn [1], line 149\u001b[0m, in \u001b[0;36mTrainer.create_activation_function\u001b[0;34m(activation_str)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_activation_function\u001b[39m(activation_str: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m activation_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m activation_str \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mReLU()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_tensor, normalize, affine\n",
    "from PIL import Image\n",
    "from typing import Tuple, List, NamedTuple\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from urllib import request\n",
    "import torch.nn as nn\n",
    "\n",
    "# Seed all random number generators\n",
    "np.random.seed(197331)\n",
    "torch.manual_seed(197331)\n",
    "random.seed(197331)\n",
    "\n",
    "\n",
    "class NetworkConfiguration(NamedTuple):\n",
    "    n_channels: Tuple[int, ...] = (16, 32, 48)\n",
    "    kernel_sizes: Tuple[int, ...] = (3, 3, 3)\n",
    "    strides: Tuple[int, ...] = (1, 1, 1)\n",
    "    dense_hiddens: Tuple[int, ...] = (256, 256)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 network_type: str = \"mlp\",\n",
    "                 net_config: NetworkConfiguration = NetworkConfiguration(),\n",
    "                 lr: float = 0.001,\n",
    "                 batch_size: int = 128,\n",
    "                 activation_name: str = \"relu\"):\n",
    "        self.train, self.test = self.load_dataset()\n",
    "        self.network_type = network_type\n",
    "        activation_function = self.create_activation_function(activation_name)\n",
    "        input_dim = self.train[0].shape[1:]\n",
    "        if network_type == \"mlp\":\n",
    "            self.network = self.create_mlp(input_dim[0]*input_dim[1]*input_dim[2], \n",
    "                                           net_config,\n",
    "                                           activation_function)\n",
    "        elif network_type == \"cnn\":\n",
    "            self.network = self.create_cnn(input_dim[0], \n",
    "                                           net_config, \n",
    "                                           activation_function)\n",
    "        else:\n",
    "            raise ValueError(\"Network type not supported\")\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=lr)\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_logs = {'train_loss': [], 'test_loss': [],\n",
    "                           'train_mae': [], 'test_mae': []}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset() -> Tuple[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        if not os.path.exists('./rotated_fashion_mnist'):\n",
    "            url = 'https://drive.google.com/u/0/uc?id=1NQPmr01eIafQKeH9C9HR0lGuB5z6mhGb&export=download&confirm=t&uuid=645ff20a-d47b-49f0-ac8b-4a7347529c8e&at=AHV7M3d_Da0D7wowJlTzzZxDky5c:1669325231545'\n",
    "            with request.urlopen(url) as f:\n",
    "                with open('./rotated_fashion_mnist.zip', 'wb') as out:\n",
    "                    out.write(f.read())\n",
    "            with zipfile.ZipFile('./rotated_fashion_mnist.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall()\n",
    "            os.remove('./rotated_fashion_mnist.zip')\n",
    "            \n",
    "        datapath = './rotated_fashion_mnist'\n",
    "\n",
    "        def get_paths_and_rots(split: str) -> List[Tuple[str, float]]:\n",
    "            image_paths, rots = [], []\n",
    "            files = os.listdir(os.path.join(datapath, split))\n",
    "            for file in files:\n",
    "                image_paths.append(os.path.join(datapath, split, file))\n",
    "                rots.append(float(file.split('_')[1].split('.')[0]))\n",
    "            return image_paths, rots\n",
    "        \n",
    "        def to_tensors(image_paths: List[str], rots: List[float]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "            images = [normalize(to_tensor(Image.open(path)), (0.5,), (0.5,)) \n",
    "                      for path in image_paths]\n",
    "            images = torch.stack(images)\n",
    "            labels = torch.tensor(rots).view(-1, 1)\n",
    "            return images, labels\n",
    "\n",
    "        X_train, y_train = to_tensors(*get_paths_and_rots('train'))\n",
    "        X_test, y_test = to_tensors(*get_paths_and_rots('test'))\n",
    "        \n",
    "        # Normalize y for easier training\n",
    "        mean, std = y_train.mean(), y_train.std()\n",
    "        y_train = (y_train - mean) / std\n",
    "        y_test = (y_test - mean) / std\n",
    "        \n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_mlp(input_dim: int, net_config: NetworkConfiguration,\n",
    "                   activation: torch.nn.Module) -> torch.nn.Module:\n",
    "        \"\"\"\n",
    "        Create a multi-layer perceptron (MLP) network.\n",
    "\n",
    "        :param net_config: a NetworkConfiguration named tuple. Only the field 'dense_hiddens' will be used.\n",
    "        :param activation: The activation function to use.\n",
    "        :return: A PyTorch model implementing the MLP.\n",
    "        \"\"\"\n",
    "        # TODO write code here\n",
    "        network = []\n",
    "        print('Pass')\n",
    "        network.append(nn.Flatten())\n",
    "        for i in range(len(net_config.dense_hiddens)):\n",
    "            if i==0:\n",
    "                network.append(nn.Linear(input_dim, net_config.dense_hiddens[0]))\n",
    "            else:\n",
    "                network.append(nn.Linear(net_config.dense_hiddens[i-1], net_config.dense_hiddens[i]))\n",
    "            network.append(activation)\n",
    "        network.append(nn.Linear(net_config.dense_hiddens[-1], 1))\n",
    "        full_network = nn.Sequential(*network)\n",
    "        return full_network\n",
    "\n",
    "    @staticmethod\n",
    "    def create_cnn(in_channels: int, net_config: NetworkConfiguration,\n",
    "                   activation: torch.nn.Module) -> torch.nn.Module:\n",
    "        \"\"\"\n",
    "        Create a convolutional network.\n",
    "\n",
    "        :param in_channels: The number of channels in the input image.\n",
    "        :param net_config: a NetworkConfiguration specifying the architecture of the CNN.\n",
    "        :param activation: The activation function to use.\n",
    "        :return: A PyTorch model implementing the CNN.\n",
    "        \"\"\"\n",
    "        network = []\n",
    "        network.append(nn.Conv2d(in_channels, net_config.n_channels[0], net_config.kernel_sizes[0], stride=net_config.strides[0]))\n",
    "        network.append(activation)\n",
    "        for i in range(1, len(net_config.n_channels)):\n",
    "          network.append(nn.MaxPool2d(kernel_size=2))\n",
    "          network.append(nn.Conv2d(net_config.n_channels[i-1], net_config.n_channels[i], net_config.kernel_sizes[i], stride=net_config.strides[i]))\n",
    "          network.append(activation)\n",
    "        network.append(nn.AdaptiveMaxPool2d((4, 4)))\n",
    "        network.append(nn.Flatten())\n",
    "        input_size = 4 * 4 * net_config.n_channels[-1]\n",
    "        for i in range(len(net_config.dense_hiddens)):\n",
    "          if i==0:\n",
    "            network.append(nn.Linear(input_size, net_config.dense_hiddens[0]))\n",
    "          else:\n",
    "            network.append(nn.Linear(net_config.dense_hiddens[i-1], net_config.dense_hiddens[i]))\n",
    "          network.append(activation)\n",
    "        network.append(nn.Linear(net_config.dense_hiddens[-1], 1))      \n",
    "        full_network = nn.Sequential(*network)\n",
    "        return full_network\n",
    "\n",
    "    @staticmethod\n",
    "    def create_activation_function(activation_str: str) -> torch.nn.Module:\n",
    "#         assert activation_str not in ['relu', 'tanh', 'sigmoid']\n",
    "        if activation_str == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif activation_str == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation_str == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        \n",
    "    def compute_loss_and_mae(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # TODO WRITE CODE HERE\n",
    "        outputs = self.network(X)\n",
    "        calculate_loss = nn.MSELoss() \n",
    "        output = calculate_loss(outputs, y)\n",
    "        calculate_error = nn.L1Loss()\n",
    "        mae_error = calculate_error(outputs, y)\n",
    "\n",
    "        return output, mae_error\n",
    "\n",
    "    def training_step(self, X_batch: torch.Tensor, y_batch: torch.Tensor):\n",
    "        # TODO WRITE CODE HERE\n",
    "        self.optimizer.zero_grad()\n",
    "        loss, _ = self.compute_loss_and_mae(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def log_metrics(self, X_train: torch.Tensor, y_train: torch.Tensor,\n",
    "                    X_test: torch.Tensor, y_test: torch.Tensor) -> None:\n",
    "        self.network.eval()\n",
    "        with torch.inference_mode():\n",
    "            train_loss, train_mae = self.compute_loss_and_mae(X_train, y_train)\n",
    "            test_loss, test_mae = self.compute_loss_and_mae(X_test, y_test)\n",
    "        self.train_logs['train_mae'].append(train_mae.item())\n",
    "        self.train_logs['test_mae'].append(test_mae.item())\n",
    "        self.train_logs['train_loss'].append(train_loss.item())\n",
    "        self.train_logs['test_loss'].append(test_loss.item())\n",
    "\n",
    "    def train_loop(self, n_epochs: int):\n",
    "        # Prepare train and validation data\n",
    "        X_train, y_train = self.train\n",
    "        X_test, y_test = self.test\n",
    "\n",
    "        n_batches = int(np.ceil(X_train.shape[0] / self.batch_size))\n",
    "\n",
    "        self.log_metrics(X_train[:2000], y_train[:2000], X_test, y_test)\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            for batch in range(n_batches):\n",
    "                minibatchX = X_train[self.batch_size * batch:self.batch_size * (batch + 1), :]\n",
    "                minibatchY = y_train[self.batch_size * batch:self.batch_size * (batch + 1), :]\n",
    "                self.training_step(minibatchX, minibatchY)\n",
    "            self.log_metrics(X_train[:2000], y_train[:2000], X_test, y_test)\n",
    "        return self.train_logs\n",
    "\n",
    "    def evaluate(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # TODO WRITE CODE HERE\n",
    "        loss, mae = self.compute_loss_and_mae(X, y)\n",
    "        loss = loss.detach()\n",
    "\n",
    "        return loss, mae\n",
    "\n",
    "\n",
    "    def test_equivariance(self):\n",
    "        from functools import partial\n",
    "        test_im = (self.train[0][0] + 1) / 2\n",
    "        conv = torch.nn.Conv2d(kernel_size=3, in_channels=1, out_channels=1, stride=1, padding=0)\n",
    "        fullconv_model = lambda x: torch.relu(conv((torch.relu(conv((x))))))\n",
    "        model = fullconv_model\n",
    "\n",
    "        shift_amount = 5\n",
    "        shift = partial(affine, angle=0, translate=(shift_amount, shift_amount), scale=1, shear=0)\n",
    "        rotation = partial(affine, angle=90, translate=(0, 0), scale=1, shear=0)\n",
    "\n",
    "        # TODO CODE HERE\n",
    "        pass\n",
    "\n",
    "def main():\n",
    "    net_config = NetworkConfiguration(n_channels = (16, 32, 48),\n",
    "                                        kernel_sizes = (3, 3, 3),\n",
    "                                        strides = (1, 1, 1),\n",
    "                                        dense_hiddens = (128, 128)\n",
    "                                        )\n",
    "    trainer_obj = Trainer(network_type = \"mlp\",\n",
    "                             net_config = net_config,\n",
    "                             lr = 0.01,\n",
    "                             batch_size = 128,\n",
    "                             activation_name = \"relu\")\n",
    "    train_logs = trainer_obj.train_loop(50)\n",
    "    print(train_logs)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ffec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
