{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a88b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_loader import load_modeling_data\n",
    "from utilities.text_cleaner import advanced_data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac45377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c30f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input, Conv1D, GlobalMaxPool1D, Dropout, concatenate, Layer, InputSpec, CuDNNLSTM\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import activations, initializers, regularizers, constraints\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc84774",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_modeling_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bf6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(advanced_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a76f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_labels['target'] = le.fit_transform(train_labels['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605d8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0760685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d764ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e7d4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29be2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer.texts_to_sequences(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a166e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_val = tokenizer.texts_to_sequences(X_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550137c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "df_val = pad_sequences(tokenized_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6debfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 7\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b545ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 100, 100)     2000000     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 100, 100)     0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 98, 200)      60200       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 96, 200)      120200      ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 94, 256)      153856      ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 92, 256)      196864      ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 45, 512)      393728      ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " cu_dnnlstm_4 (CuDNNLSTM)       (None, 512)          2101248     ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " cu_dnnlstm_5 (CuDNNLSTM)       (None, 512)          2101248     ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1024)         0           ['cu_dnnlstm_4[0][0]',           \n",
      "                                                                  'cu_dnnlstm_5[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 1024)         0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           65600       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 3)            195         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,193,139\n",
      "Trainable params: 7,193,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cudnnlstm_model(conv_layers = 2, max_dilation_rate = 3):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, trainable=True)(inp)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(2*embed_size, kernel_size = 3)(x)\n",
    "    prefilt = Conv1D(2*embed_size, kernel_size = 3)(x)\n",
    "    x = prefilt\n",
    "    for strides in [1, 1, 2]:\n",
    "        x = Conv1D(128*2**(strides), strides = strides, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_size=3, kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n",
    "    x_f = CuDNNLSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)  \n",
    "    x_b = CuDNNLSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n",
    "    x = concatenate([x_f, x_b])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(3, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "cudnnlstm_model = cudnnlstm_model()\n",
    "cudnnlstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "443c2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"late_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f0b34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_oh = to_categorical(y_train['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7da0b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.7709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 23:50:06.794949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46489, saving model to late_weights.hdf5\n",
      "1301/1301 [==============================] - 1400s 1s/step - loss: 0.4908 - accuracy: 0.7709 - val_loss: 0.4649 - val_accuracy: 0.7849\n",
      "Epoch 2/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.7957\n",
      "Epoch 2: val_loss improved from 0.46489 to 0.45050, saving model to late_weights.hdf5\n",
      "1301/1301 [==============================] - 1407s 1s/step - loss: 0.4478 - accuracy: 0.7957 - val_loss: 0.4505 - val_accuracy: 0.7957\n",
      "Epoch 3/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8081\n",
      "Epoch 3: val_loss improved from 0.45050 to 0.44580, saving model to late_weights.hdf5\n",
      "1301/1301 [==============================] - 1433s 1s/step - loss: 0.4250 - accuracy: 0.8081 - val_loss: 0.4458 - val_accuracy: 0.7939\n",
      "Epoch 4/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8148\n",
      "Epoch 4: val_loss did not improve from 0.44580\n",
      "1301/1301 [==============================] - 1426s 1s/step - loss: 0.4146 - accuracy: 0.8148 - val_loss: 0.4560 - val_accuracy: 0.7911\n",
      "Epoch 5/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.8238\n",
      "Epoch 5: val_loss did not improve from 0.44580\n",
      "1301/1301 [==============================] - 1447s 1s/step - loss: 0.3979 - accuracy: 0.8238 - val_loss: 0.4577 - val_accuracy: 0.7905\n",
      "Epoch 6/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8308\n",
      "Epoch 6: val_loss did not improve from 0.44580\n",
      "1301/1301 [==============================] - 1461s 1s/step - loss: 0.3841 - accuracy: 0.8308 - val_loss: 0.4635 - val_accuracy: 0.7914\n",
      "Epoch 7/7\n",
      "1301/1301 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8363\n",
      "Epoch 7: val_loss did not improve from 0.44580\n",
      "1301/1301 [==============================] - 1464s 1s/step - loss: 0.3752 - accuracy: 0.8363 - val_loss: 0.4708 - val_accuracy: 0.7892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x365912400>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cudnnlstm_model.fit(df_train, y_train_oh, batch_size=batch_size, epochs=epochs, shuffle = True, validation_split=0.20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105229f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
