{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdc52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "\n",
    "# Importing custom utility functions\n",
    "from utilities.data_loader import load_modeling_data, load_testing_data, prepare_kaggle_submission\n",
    "from utilities.text_cleaner import advanced_data_cleaning\n",
    "\n",
    "# Importing modeling utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Raw training and testing data\n",
    "train_data, train_labels = load_modeling_data()\n",
    "test_data = load_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a0f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_labels['target'] = le.fit_transform(train_labels['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for validation\n",
    "# Using 20% data for validation and keeping random_state 8 for consistency in stated results in report.\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8af4a7",
   "metadata": {},
   "source": [
    "# Experiment 1: Making Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5ec7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Baseline Naive Bayes-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initializing Bag of Words instance (CountVectorizer)\n",
    "print('-'*175+'Baseline Naive Bayes'+'-'*175)\n",
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d560ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and training the bag of words\n",
    "X_train_bow = bow.fit_transform(X_train['text'])\n",
    "X_val_bow = bow.transform(X_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a0b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the bag of words matrix:  (832258, 440087)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the bag of words matrix: \",X_train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47abaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing naive bayes classifier\n",
    "nb_clf_1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccdb2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier with default parameters\n",
    "nb_clf_1.fit(X_train_bow, y_train['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be7f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pridicting from the validation set\n",
    "y_pred_val = nb_clf_1.predict(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9562ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7783288876072382\n",
      "Confusion Matrix: \n",
      "[[85180     1 18466]\n",
      " [    1     0    10]\n",
      " [27643     1 76763]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79    103647\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.81      0.74      0.77    104407\n",
      "\n",
      "    accuracy                           0.78    208065\n",
      "   macro avg       0.52      0.52      0.52    208065\n",
      "weighted avg       0.78      0.78      0.78    208065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the results\n",
    "print('Accuracy score: ', accuracy_score(y_val['target'].values, y_pred_val))\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix(y_val['target'].values, y_pred_val))\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_val['target'].values, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "206bcf88",
   "metadata": {},
   "source": [
    "# Experiment 2: hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933646c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Naive Bayes Hyper parameter tuning-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*175+'Naive Bayes Hyper parameter tuning'+'-'*175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93df5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining search grid\n",
    "grid = {\n",
    "    'alpha': [0, 0.25, 1, 2, 3, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fda7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing bayesian search\n",
    "nb_clf_2 = BayesSearchCV(MultinomialNB(), grid, n_iter= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fabbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training for best hyperparameters\n",
    "_ = nb_clf_2.fit(X_train_bow, y_train['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e105e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found hyperparameters are: \n",
      "OrderedDict([('alpha', 2.0)])\n"
     ]
    }
   ],
   "source": [
    "# printing the best found parameters\n",
    "print(\"Best found hyperparameters are: \")\n",
    "print(nb_clf_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26a43fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_2 = MultinomialNB(alpha=2.0)\n",
    "nb_clf_2.fit(X_train_bow, y_train['target'].values)\n",
    "y_val_pred = nb_clf_2.predict(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e36ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7788431499771706\n",
      "Confusion Matrix: \n",
      "[[85853     0 17794]\n",
      " [    2     0     9]\n",
      " [28209     1 76197]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79    103647\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.81      0.73      0.77    104407\n",
      "\n",
      "    accuracy                           0.78    208065\n",
      "   macro avg       0.52      0.52      0.52    208065\n",
      "weighted avg       0.78      0.78      0.78    208065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the results\n",
    "print('Accuracy score: ', accuracy_score(y_val['target'].values, y_val_pred))\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix(y_val['target'].values, y_val_pred))\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_val['target'].values, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2651109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e78a2ef",
   "metadata": {},
   "source": [
    "# Experiment 3: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a85c197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Naive Bayes with stemming-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*175+'Naive Bayes with stemming'+'-'*175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0789cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stemming function\n",
    "def stemmer(text):\n",
    "    porter = PorterStemmer()\n",
    "    ls = [porter.stem(word) for word in text.split()]\n",
    "    return ' '.join(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd1c4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making copy of dataframe and applying stemming to each text documents\n",
    "X_train_stem = X_train.copy()\n",
    "X_val_stem = X_val.copy()\n",
    "X_train_stem['text'] = X_train_stem['text'].apply(stemmer)\n",
    "X_val_stem['text'] = X_val_stem['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec53f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train_stem['text'])\n",
    "X_val_bow = bow.transform(X_val_stem['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bceda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_3 = MultinomialNB(alpha=2.0)\n",
    "nb_clf_3.fit(X_train_bow, y_train['target'].values)\n",
    "y_val_pred = nb_clf_3.predict(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a044507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7749549419652513\n",
      "Confusion Matrix: \n",
      "[[85791     0 17856]\n",
      " [    2     0     9]\n",
      " [28957     0 75450]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79    103647\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.81      0.72      0.76    104407\n",
      "\n",
      "    accuracy                           0.77    208065\n",
      "   macro avg       0.52      0.52      0.52    208065\n",
      "weighted avg       0.78      0.77      0.77    208065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Printing the results\n",
    "print('Accuracy score: ', accuracy_score(y_val['target'].values, y_val_pred))\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix(y_val['target'].values, y_val_pred))\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_val['target'].values, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f26837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420294a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e2518bc",
   "metadata": {},
   "source": [
    "# Experiment 4: Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc3d3b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Naive Bayes with lemmatizing-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*175+'Naive Bayes with lemmatizing'+'-'*175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4cb106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining lemmatizing function\n",
    "def lemmatizer(text):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    ls = [wordnet.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfaf23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making copy of dataframe and applying lemmatizing to each text documents\n",
    "X_train_lemmatize = X_train.copy()\n",
    "X_val_lemmatize = X_val.copy()\n",
    "X_train_lemmatize['text'] = X_train_lemmatize['text'].apply(lemmatizer)\n",
    "X_val_lemmatize['text'] = X_val_lemmatize['text'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e836baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train_lemmatize['text'])\n",
    "X_val_bow = bow.transform(X_val_lemmatize['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e6c7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_4 = MultinomialNB(alpha=2.0)\n",
    "nb_clf_4.fit(X_train_bow, y_train['target'].values)\n",
    "y_val_pred = nb_clf_4.predict(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac932dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7782519885612669\n",
      "Confusion Matrix: \n",
      "[[85936     0 17711]\n",
      " [    1     0    10]\n",
      " [28416     0 75991]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79    103647\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.81      0.73      0.77    104407\n",
      "\n",
      "    accuracy                           0.78    208065\n",
      "   macro avg       0.52      0.52      0.52    208065\n",
      "weighted avg       0.78      0.78      0.78    208065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Printing the results\n",
    "print('Accuracy score: ', accuracy_score(y_val['target'].values, y_val_pred))\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix(y_val['target'].values, y_val_pred))\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_val['target'].values, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdb558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc02232",
   "metadata": {},
   "source": [
    "# Experiment 5: Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa4a1e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Naive Bayes with stop words removal-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*175+'Naive Bayes with stop words removal'+'-'*175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7e381a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stopwords remover function\n",
    "def remove_stopwords(text):\n",
    "    text = text.lower()\n",
    "    ls = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44b6eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making copy of dataframe and applying lemmatizing to each text documents\n",
    "X_train_stop = X_train.copy()\n",
    "X_val_stop = X_val.copy()\n",
    "X_train_stop['text'] = X_train_stop['text'].apply(remove_stopwords)\n",
    "X_val_stop['text'] = X_val_stop['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4b81668",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train_stop['text'])\n",
    "X_val_bow = bow.transform(X_val_stop['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90eaf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_5 = MultinomialNB(alpha=2.0)\n",
    "nb_clf_5.fit(X_train_bow, y_train['target'].values)\n",
    "y_val_pred = nb_clf_5.predict(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f68e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7696296830317448\n",
      "Confusion Matrix: \n",
      "[[83465     0 20182]\n",
      " [    2     0     9]\n",
      " [27739     0 76668]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78    103647\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.79      0.73      0.76    104407\n",
      "\n",
      "    accuracy                           0.77    208065\n",
      "   macro avg       0.51      0.51      0.51    208065\n",
      "weighted avg       0.77      0.77      0.77    208065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Printing the results\n",
    "print('Accuracy score: ', accuracy_score(y_val['target'].values, y_val_pred))\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix(y_val['target'].values, y_val_pred))\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_val['target'].values, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163adb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2ce8f2b",
   "metadata": {},
   "source": [
    "# Experiment 6: Advanced Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eba0dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Naive Bayes with advanced text cleaning-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*175+'Naive Bayes with advanced text cleaning'+'-'*175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bd82115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making copy of dataframe and applying lemmatizing to each text documents\n",
    "X_train_clean = X_train.copy()\n",
    "X_val_clean = X_val.copy()\n",
    "X_train_clean['text'] = X_train_clean['text'].apply(advanced_data_cleaning)\n",
    "X_val_clean['text'] = X_val_clean['text'].apply(advanced_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1120e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train_clean['text'])\n",
    "X_val_bow = bow.transform(X_val_clean['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd65d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_6 = MultinomialNB(alpha=2.0)\n",
    "nb_clf_6.fit(X_train_bow, y_train['target'].values)\n",
    "y_val_pred = nb_clf_6.predict(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bcb37f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7783673371302238\n",
      "Confusion Matrix: \n",
      "[[85346     0 18301]\n",
      " [    4     0     7]\n",
      " [27802     0 76605]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79    103647\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.81      0.73      0.77    104407\n",
      "\n",
      "    accuracy                           0.78    208065\n",
      "   macro avg       0.52      0.52      0.52    208065\n",
      "weighted avg       0.78      0.78      0.78    208065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Printing the results\n",
    "print('Accuracy score: ', accuracy_score(y_val['target'].values, y_val_pred))\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix(y_val['target'].values, y_val_pred))\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_val['target'].values, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'models/naive_bayes+BOW.sav'\n",
    "joblib.dump(nb_clf_6, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b832c",
   "metadata": {},
   "source": [
    "# Finalizing model for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fba9cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes experiments completed, starting retraining on full training data with best model for kaggle submission..\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes experiments completed, starting retraining on full training data with best model for kaggle submission..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c986059",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = train_data.copy()\n",
    "X_test_final = test_data.copy()\n",
    "X_train_final['text'] = X_train_final['text'].apply(advanced_data_cleaning)\n",
    "X_test_final['text'] = X_test_final['text'].apply(advanced_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98d2f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train_final['text'])\n",
    "X_test_bow = bow.transform(X_test_final['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "992079b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf_6 = MultinomialNB(alpha=3.0)\n",
    "nb_clf_6.fit(X_train_bow, train_labels['target'].values)\n",
    "y_test_pred = nb_clf_6.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c82d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_kaggle_submission(y_test_pred, 'final-naive-bayes-advance-clean-bow-hp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a50fae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_bow = X_train_bow.astype('float32')\n",
    "X_val_bow = X_val_bow.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476db195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7442749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
